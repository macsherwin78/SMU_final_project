<!DOCTYPE HTML>
<!--
	Intensify by TEMPLATED
	templated.co @templatedco
	Released for free under the Creative Commons Attribution 3.0 license (templated.co/license)
-->
<html>
	<head>
		<title>Trees</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1" />
		<link rel="stylesheet" href="../static/css/main.css" />
	</head>
	<body class="subpage">

		<!-- Header -->
			<header id="header">
				<nav class="left">
					<a href="#menu"><span>Menu</span></a>
				</nav>
				<a href="{{url_for('index')}}" class="logo">Analysis of Airbnb</a>
			</header>

		<!-- Menu -->
			<nav id="menu">
				<ul class="links">
				<li><a href="{{url_for('index')}}">Home</a></li>
                <li><a href="{{url_for('machine_learning')}}">Machine Learning</a></li>
                <li><a href="{{url_for('linear_regression')}}">Linear Regression</a></li>
                <li><a href="{{url_for('trees')}}">Trees</a></li>
                <li><a href="{{url_for('knn')}}">KNN</a></li>
                <li><a href="{{url_for('gradient_boost')}}">Gradient Boost</a></li>
                <li><br></li>
				<li><h4><a href="{{url_for('calculator')}}">fAirbnb Calculator</a></h4></li>
                </ul>
			</nav>

		<!-- Main -->
        <section id="main" class="wrapper">
            <div class="inner">
                <header class="align-center">
                    <h1>Trees</h1>
                </header>
                
                <div class="row">
					<div class="6u 12u$(small)">
                        <h2 id="content">Decision Tree</h2>

                            <p>
                                Decision Trees are a non-parametric supervised machine learning model used 
                                for classification and regression. This model learns in a hierarchical fashion 
                                by repeatedly splitting the chosen dataset into separate branches to learn non-linear 
                                relationships. </br> The result is a model that predicts the value of a target variable, 
                                in this case being price, by learning simple decision rules inferred from data features, 
                                in this case neighborhood group, room type, or days available during the year.
                            </p>

                            <p>
                                We encoded our data to fit the requirements of this model. 
                                We did not reach the minimum 85% R2 Score to consider this model effective. </br>
                                <b>Our R2 Score totaled 7.322849209336635 or 7%.</b>
                            </p>

                            <h2>Strengths: </h2>
                            <h4>can determine strength of predictors, can predict future trends, can be regularized to avoid overfitting, can be easily updated with new data.</h4>
                        </br>
                            <h2>Weaknesses:  </h2>
                            <h4>poor performance in non-linear relationships, not naturally flexible to capture complex patterns</h4>
					</div>
					
					<div class="6u$ 12u$(small)">
                        <h2 id="content">Random Forest</h2>

                        <p>Random Forest is a supervised machine learning model that averages the result of any chosen number of 
                            Decision Trees using randomly selected observations and selected column features. 
                            The result is a final average of all values predicted by all present trees  in the Random Forest. 
                        </p><p>
                            The most important parameter of the RandomForestRegressor class is the n_estimators parameter, 
                            which defines the number of Decision Trees to be used. With 100 trees, 
                            the regressor score is -0.097, weaker than a straight line. With 200 trees, 
                            the regressor score is -0.093, which is a minimal improvement.  
                        </p>
        
                        <h2>Strengths: </h2>
                        <h4>reduced overall biasedness since each Random Forest is trained on a subset of data and relies on “the crowd”, 
                            unlikely to destabilize when new data added, 
                            works well when categorical and numerical features are present </h4>
                    </br>
                        <h2>Weaknesses:  </h2>
                        <h4>their complexity, subsequent time required to train </h4>
					</div>
					</div>

            </div>
        </section>

    <!-- Footer -->
    <footer id="footer">
        <div class="inner">
            <h2>SMU</br>Data Science Bootcamp</h2>
            <ul class="actions">
                <li><span class="icon fa-phone"></span> <a href="#">(214) 775-9982</a></li>
                <li><span class="icon fa-envelope"></span> <a href="#">www.smu.edu/Pro</a></li>
                <li><span class="icon fa-map-marker"></span> Dallas, TX 75205</li>
            </ul>
        </div>
        <div class="copyright">
            &copy; Untitled. Design <a href="https://templated.co">TEMPLATED</a>. Images <a href="https://unsplash.com">Unsplash</a>.
        </div>
    </footer>

    <!-- Scripts -->
    <script src="static/js/jquery.min.js"></script>
    <script src="static/js/jquery.scrolly.min.js"></script>
    <script src="static/js/skel.min.js"></script>
    <script src="static/js/util.js"></script>
    <script src="static/js/main.js"></script>

</body>
</html>